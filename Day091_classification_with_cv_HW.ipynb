{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day091_classification_with_cv_HW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meganhsu/ML100-Days/blob/master/Day091_classification_with_cv_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Cci8pIuIaPWO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 作業\n",
        "嘗試比較用 color histogram 和 HOG 特徵來訓練的 SVM 分類器在 cifar10 training 和 testing data 上準確度的差別"
      ]
    },
    {
      "metadata": {
        "id": "UPvXbJ_GaPWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7742bb2a-172f-411d-f63c-970ff4020f9e"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # 使用 CPU\n",
        "\n",
        "import numpy as np\n",
        "import cv2 # 載入 cv2 套件\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1cOWlZSPaPWU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l80JYDGjaPWX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 產生直方圖特徵的訓練資料"
      ]
    },
    {
      "metadata": {
        "id": "8INXNRJiaPWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train_histogram = []\n",
        "x_test_histogram = []\n",
        "\n",
        "# 對於所有訓練資料\n",
        "for i in range(len(x_train)):\n",
        "    chans = cv2.split(x_train[i]) # 把圖像的 3 個 channel 切分出來\n",
        "    # 對於所有 channel\n",
        "    hist_feature = []\n",
        "    for chan in chans:\n",
        "        # 計算該 channel 的直方圖\n",
        "        hist = cv2.calcHist([chan], [0], None, [16], [0, 256]) # 切成 16 個 bin\n",
        "        hist_feature.extend(hist.flatten())\n",
        "    # 把計算的直方圖特徵收集起來\n",
        "    x_train_histogram.append(hist_feature)\n",
        "\n",
        "# 對於所有測試資料也做一樣的處理\n",
        "for i in range(len(x_test)):\n",
        "    chans = cv2.split(x_test[i]) # 把圖像的 3 個 channel 切分出來\n",
        "    # 對於所有 channel\n",
        "    hist_feature = []\n",
        "    for chan in chans:\n",
        "        # 計算該 channel 的直方圖\n",
        "        hist = cv2.calcHist([chan], [0], None, [16], [0, 256]) # 切成 16 個 bin\n",
        "        hist_feature.extend(hist.flatten())\n",
        "    x_test_histogram.append(hist_feature)\n",
        "\n",
        "x_train_histogram = np.array(x_train_histogram)\n",
        "x_test_histogram = np.array(x_test_histogram)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L6fGAInjaPWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 產生 HOG 特徵的訓練資料\n",
        "* HOG 特徵通過計算和統計圖像局部區域的梯度方向直方圖來構建特徵，具體細節不在我們涵蓋的範圍裡面，有興趣的同學請參考[補充資料](https://www.cnblogs.com/zyly/p/9651261.html)哦"
      ]
    },
    {
      "metadata": {
        "id": "ijWpW2S8aPWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SZ=20\n",
        "bin_n = 16 # Number of bins\n",
        "\n",
        "def hog(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
        "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
        "    mag, ang = cv2.cartToPolar(gx, gy)\n",
        "    bins = np.int32(bin_n*ang/(2*np.pi))    # quantizing binvalues in (0...16)\n",
        "    bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:]\n",
        "    mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:]\n",
        "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
        "    hist = np.hstack(hists)     # hist is a 64 bit vector\n",
        "    return hist.astype(np.float32)\n",
        "\n",
        "x_train_hog = np.array([hog(x) for x in x_train])\n",
        "x_test_hog = np.array([hog(x) for x in x_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z-YrNEwGaPWf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### SVM model\n",
        "* SVM 是機器學習中一個經典的分類算法，具體細節有興趣可以參考 [該知乎上的解釋](https://www.zhihu.com/question/21094489)，我們這裡直接調用 opencv 中實現好的函數"
      ]
    },
    {
      "metadata": {
        "id": "g-P4p963aPWg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 用 histogram 特徵訓練 SVM 模型\n",
        "* 訓練過程可能會花點時間，請等他一下"
      ]
    },
    {
      "metadata": {
        "id": "VvaABQPcaPWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SVM_hist = cv2.ml.SVM_create()\n",
        "SVM_hist.setKernel(cv2.ml.SVM_LINEAR)\n",
        "SVM_hist.setGamma(5.383)\n",
        "SVM_hist.setType(cv2.ml.SVM_C_SVC)\n",
        "SVM_hist.setC(2.67)\n",
        "\n",
        "#training\n",
        "SVM_hist.train(x_train_histogram, cv2.ml.ROW_SAMPLE, y_train)\n",
        "\n",
        "# prediction\n",
        "_, y_hist_train = SVM_hist.predict(x_train_histogram)\n",
        "_, y_hist_test = SVM_hist.predict(x_test_histogram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eyk4NV3PaPWk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 用 HOG 特徵訓練 SVM 模型\n",
        "* 訓練過程可能會花點時間，請等他一下"
      ]
    },
    {
      "metadata": {
        "id": "cgqty0ULaPWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SVM_hog = cv2.ml.SVM_create()\n",
        "SVM_hog.setKernel(cv2.ml.SVM_LINEAR)\n",
        "SVM_hog.setGamma(5.383)\n",
        "SVM_hog.setType(cv2.ml.SVM_C_SVC)\n",
        "SVM_hog.setC(2.67)\n",
        "\n",
        "#training\n",
        "SVM_hog.train(x_train_hog, cv2.ml.ROW_SAMPLE, y_train)\n",
        "\n",
        "# prediction\n",
        "_, y_hog_train = SVM_hog.predict(x_train_hog)\n",
        "_, y_hog_test = SVM_hog.predict(x_test_hog)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3FqVS_YWaWH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5fc72976-b30e-45d4-e4f4-cda4a4ede833"
      },
      "cell_type": "code",
      "source": [
        "print(\"histogram 特徵+SVM \")\n",
        "print(f\"Training acc = {np.sum(y_hist_train == y_train) / len(y_train) * 100: .2f}%\")\n",
        "print(f\"Testing acc = {np.sum(y_hist_test == y_test) / len(y_test) * 100: .2f}%\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "histogram 特徵+SVM \n",
            "Training acc =  12.08%\n",
            "Testing acc =  12.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sB29ULvzaXsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1905fd5a-57c1-4c42-e6f2-88af86f9f86c"
      },
      "cell_type": "code",
      "source": [
        "print(\"HOG 特徵+SVM\")\n",
        "print(f\"Training acc = {np.sum(y_hog_train == y_train) / len(y_train) * 100: .2f}%\")\n",
        "print(f\"Testing acc = {np.sum(y_hog_test == y_test) / len(y_test) * 100: .2f}%\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HOG 特徵+SVM\n",
            "Training acc =  23.62%\n",
            "Testing acc =  23.18%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "854FJLwiaZEm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}